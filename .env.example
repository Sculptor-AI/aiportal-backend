# AI Portal Backend Configuration

# Database
DATABASE_PATH=./database/aiportal.db

# Authentication (CHANGE THESE IN PRODUCTION!)
JWT_SECRET=your-super-secret-jwt-key-change-in-production-please-make-this-very-long-and-random-string-here

# Server Configuration
NODE_ENV=development
PORT=3000

# SSL/HTTPS Configuration (optional)
# Generate certificates using: ./ssl/generate-ssl-certs.sh
# SSL_CERT_PATH=./ssl/server.crt
# SSL_KEY_PATH=./ssl/server.key

# API Keys for External Providers (Optional - leave blank to use OpenRouter fallback)
# Get these from the respective provider websites:

# OpenRouter (fallback for all models) - Get from: https://openrouter.ai/
OPENROUTER_API_KEY=sk-or-v1-your-openrouter-key-here

# Anthropic (for direct Claude access) - Get from: https://console.anthropic.com/
ANTHROPIC_API_KEY=sk-ant-your-anthropic-key-here

# OpenAI (for direct GPT access) - Get from: https://platform.openai.com/
OPENAI_API_KEY=sk-your-openai-key-here

# Google Gemini (for direct Gemini access) - Get from: https://ai.google.dev/
GOOGLE_API_KEY=your-google-ai-studio-key-here

# Ollama Configuration (for local model inference)
# Note: HTTPS is preferred but will fall back to HTTP if unavailable
OLLAMA_BASE_URL=https://localhost:11434

# Local GGUF Model Configuration (for llama.cpp inference)
LOCAL_MODELS_PATH=./models
LLAMA_CPP_PATH=llama-server

# CORS Origins (comma-separated list of allowed origins)
# Note: HTTPS origins are preferred for security
CORS_ORIGINS=https://localhost:3009,https://localhost:3010,https://127.0.0.1:3009,https://127.0.0.1:3010

# Allowed Models (comma-separated list, leave empty to allow all latest models)
ALLOWED_MODELS=

# Rate Limiting
RATE_LIMIT_WINDOW_MS=900000
RATE_LIMIT_MAX_REQUESTS=100